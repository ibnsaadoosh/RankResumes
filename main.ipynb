{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('base': conda)",
   "metadata": {
    "interpreter": {
     "hash": "b11f76013f1207593403df959f42b4fea27784982535ba812f36c8e41478dc5b"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "loading model...\n",
      "model loaded successfully\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "\n",
    "print('loading model...')\n",
    "#loading the downloaded model\n",
    "model =  KeyedVectors.load_word2vec_format('SO_vectors_200.bin', binary=True)\n",
    "print('model loaded successfully')\n",
    "#the model is loaded. It can be used to perform all of the tasks mentioned above.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "class DocSim:\n",
    "    def __init__(self, w2v_model, stopwords=None):\n",
    "        self.w2v_model = w2v_model\n",
    "        self.stopwords = stopwords if stopwords is not None else []\n",
    "\n",
    "    def vectorize(self, doc: str) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Identify the vector values for each word in the given document\n",
    "        :param doc:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        doc = doc.lower()\n",
    "        words = [w for w in doc.split(\" \") if w not in self.stopwords]\n",
    "        word_vecs = []\n",
    "        for word in words:\n",
    "            try:\n",
    "                vec = self.w2v_model[word]\n",
    "                word_vecs.append(vec)\n",
    "            except KeyError:\n",
    "                # Ignore, if the word doesn't exist in the vocabulary\n",
    "                pass\n",
    "\n",
    "        # Assuming that document vector is the mean of all the word vectors\n",
    "        # PS: There are other & better ways to do it.\n",
    "        vector = np.mean(word_vecs, axis=0)\n",
    "        return vector\n",
    "\n",
    "    def _cosine_sim(self, vecA, vecB):\n",
    "        \"\"\"Find the cosine similarity distance between two vectors.\"\"\"\n",
    "        csim = np.dot(vecA, vecB) / (np.linalg.norm(vecA) * np.linalg.norm(vecB))\n",
    "\n",
    "        if np.isnan(np.sum(csim)):\n",
    "            return 0\n",
    "        return csim\n",
    "\n",
    "    def calculate_similarity(self, dircvs, source_doc, target_docs=None, threshold=0):\n",
    "        \"\"\"Calculates & returns similarity scores between given source document & all\n",
    "        the target documents.\"\"\"\n",
    "        if not target_docs:\n",
    "            return []\n",
    "\n",
    "        #Vectorize using Word2Vec\n",
    "        source_vec = self.vectorize(source_doc)\n",
    "        results = []\n",
    "        for i in range(len(target_docs)):\n",
    "            #Vectorize using Word2Vec\n",
    "            target_vec = self.vectorize(target_docs[i])\n",
    "            #calculating similarity using cosine similarity\n",
    "            sim_score = self._cosine_sim(source_vec, target_vec)\n",
    "            if sim_score > threshold:\n",
    "                results.append({\"score\": sim_score, \"doc\": dircvs[i]})\n",
    "            # Sort results by score in desc order\n",
    "            results.sort(key=lambda k: k[\"score\"], reverse=True)\n",
    "\n",
    "        return results\n",
    "        # dircvs[target_docs.index(doc)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Bsc degree of Computer Science or equivalent. \n\n\t\tFamiliarity with vulnerability assessment and penetration best practices \n\n\t\tExperience with vulnerability and penetration testing techniques and tools \n\n\t\t3 or more years of hands-on penetration testing experience \n\n\t\t3 or more years of hands-on red team testing experience \n\n\t\tOne of the following certificates at least (CREST, OSCP , GPEN , GIAC) \n\n\t\tCompetency in common operating systems (e.g. Windows, macOS, Linux) \n\n\t\tProficiency with at least two scripting languages (e.g. Python, Bash, JavaScript, PowerShell)\n[{'score': 0.8357759, 'doc': './CVS/penetration.docx'}, {'score': 0.81228137, 'doc': './CVS/Abdelrahman Eid CV 104.pdf'}, {'score': 0.73832136, 'doc': './CVS/Resume2019.pdf'}, {'score': 0.73459524, 'doc': './CVS/Ahmed-Ahmed.pdf'}, {'score': 0.7204977, 'doc': './CVS/PHPDeveloper-CV-Gehad-Al-Shepeny.pdf'}, {'score': 0.7137368, 'doc': './CVS/mean_stack.docx'}, {'score': 0.6440077, 'doc': './CVS/Abdullah Mustafa Zakaria Nassar Resume.pdf'}, {'score': 0.606042, 'doc': './CVS/CV-PHP-Developer.pdf'}]\n"
     ]
    }
   ],
   "source": [
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "# from DocSim import DocSim\n",
    "import textract\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "# ds = DocSim(model)\n",
    "dir_cvs = './CVS'\n",
    "\n",
    "\n",
    "ds = DocSim(model)\n",
    "\n",
    "target_docs = []\n",
    "\n",
    "def read_All_CV(filename):\n",
    "    text = textract.process(filename)\n",
    "    return text.decode('utf-8')\n",
    "\n",
    "dircvs = [join(dir_cvs, f) for f in listdir(dir_cvs) if isfile(join(dir_cvs, f))]\n",
    "\n",
    "for cv in dircvs:\n",
    "    text = read_All_CV(cv)\n",
    "    target_docs.append(text)\n",
    "\n",
    "source_doc = textract.process('source.docx')\n",
    "source_doc = source_doc.decode('utf-8')\n",
    "\n",
    "print(source_doc)\n",
    "\n",
    "sim_scores = ds.calculate_similarity(dircvs, source_doc, target_docs)\n",
    "\n",
    "print(sim_scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Bsc degree of Computer Science or equivalent.\n",
      "Familiarity with vulnerability assessment and penetration best practices\n",
      "Experience with vulnerability and penetration testing techniques and tools\n",
      "3 or more years of hands-on penetration testing experience\n",
      "3 or more years of hands-on red team testing experience\n",
      "One of the following certificates at least (CREST, OSCP , GPEN , GIAC)\n",
      "Competency in common operating systems (e.g. Windows, macOS, Linux)\n",
      "Proficiency with at least two scripting languages (e.g. Python, Bash, JavaScript, PowerShell)\n",
      "['/home/saad/Documents/fourth-year/first-term/graduation-project/model/CVS/Abdelrahman Eid CV 104.pdf', '/home/saad/Documents/fourth-year/first-term/graduation-project/model/CVS/Abdullah Mustafa Zakaria Nassar Resume.pdf', '/home/saad/Documents/fourth-year/first-term/graduation-project/model/CVS/Ahmed-Ahmed.pdf', '/home/saad/Documents/fourth-year/first-term/graduation-project/model/CVS/CV-PHP-Developer.pdf', '/home/saad/Documents/fourth-year/first-term/graduation-project/model/CVS/mean_stack.docx', '/home/saad/Documents/fourth-year/first-term/graduation-project/model/CVS/penetration.docx']\n"
     ]
    }
   ],
   "source": [
    "from tkinter.filedialog import askopenfilenames, askopenfilename\n",
    "import tkinter as tk\n",
    "import os\n",
    "import textract\n",
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "\n",
    "\n",
    "def getJobDescription(filename):\n",
    "    with open(filename) as f:\n",
    "        lines = f.readlines()\n",
    "    lines=''.join(lines)\n",
    "    print(lines)\n",
    "    entry.delete(0.0,\"end\")\n",
    "    entry.insert(0.0,lines)\n",
    "\n",
    "def openFileSelector():\n",
    "    filename = askopenfilename()\n",
    "    getJobDescription(filename)\n",
    "\n",
    "def writeSelectedCVs():\n",
    "    global CVs\n",
    "    str=\"Selected CVs\\n\"\n",
    "    for cv in CVs:\n",
    "        str+=os.path.basename(cv)+\"\\n\"\n",
    "    label=tk.Label(root,text=str)\n",
    "    canvas.create_window(1000,150, window=label)\n",
    "ds = DocSim(model)\n",
    "\n",
    "def getCVs():\n",
    "    global CVs\n",
    "    CVs = list(askopenfilenames())\n",
    "    print(CVs)\n",
    "    writeSelectedCVs()\n",
    "\n",
    "def read_All_CV(filename):\n",
    "    text = textract.process(filename)\n",
    "    return text.decode('utf-8')\n",
    "def sortCVs():\n",
    "    global CVs\n",
    "    jobDesc = entry.get(0.0,\"end\")\n",
    "    targetDocs = []\n",
    "    for cv in CVs:\n",
    "        targetDocs.append(read_All_CV(cv))\n",
    "    sim_scores = ds.calculate_similarity(CVs, jobDesc, targetDocs)\n",
    "    # print('sim = ', sim_scores)\n",
    "    str = \"Sorted CVs\\n\"\n",
    "    for cv in sim_scores:\n",
    "        str += os.path.basename(cv['doc']) + \", \" + repr(cv['score']) + \"\\n\"\n",
    "        \n",
    "    label = tk.Label(root, text=str)\n",
    "    canvas.create_window(1300, 150, window=label)\n",
    "\n",
    "\n",
    "CVs = []\n",
    "root = tk.Tk()\n",
    "\n",
    "canvas = tk.Canvas(root, width=1500, height=1000)\n",
    "canvas.pack()\n",
    "\n",
    "entry = tk.Text(root, height=30, width=70)\n",
    "\n",
    "canvas.create_window(300, 260, window=entry)\n",
    "\n",
    "button1 = tk.Button(text='Get Job Description from file', command=openFileSelector)\n",
    "button2 = tk.Button(text='Get CVs', command=getCVs)\n",
    "button3 = tk.Button(text='Sort CVs', command=sortCVs)\n",
    "x = 700\n",
    "canvas.create_window(x, 100, window=button1)\n",
    "canvas.create_window(x, 200, window=button2)\n",
    "canvas.create_window(x, 300, window=button3)\n",
    "\n",
    "root.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}